{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "import tqdm.notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(net, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(size, 1500)\n",
    "        self.l2 = nn.Linear(1500, 1000)\n",
    "        self.l3 = nn.Linear(1000, 500)\n",
    "        self.l4 = nn.Linear(500, 250)\n",
    "        self.l5 = nn.Linear(250, 250)\n",
    "        self.l6 = nn.Linear(250, 1)\n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(self.act(x))\n",
    "        x = self.l3(self.act(x))\n",
    "        x = self.l4(self.act(x))\n",
    "        x = self.l5(self.act(x))\n",
    "        x = self.l6(self.act(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(pd_arr, column_name):\n",
    "    y = torch.Tensor(np.array(pd_arr[column_name]))\n",
    "    x = torch.Tensor(np.array(pd_arr.drop([column_name], 1)))\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def read(file_name):\n",
    "    data_file = pandas.read_stata(file_name+\".dta\")\n",
    "    return data_file\n",
    "\n",
    "def process_stada(data_file): \n",
    "    \n",
    "    data_file.drop(['intmonth', 'lineno', 'hurespli', 'hrlonglk', 'serial', 'hhnum', 'qstnum', 'occurnum', 'ym', 'ym_file', 'weight', 'earnwtp', 'minsamp', 'hrsample', 'earnwt', ], 1, inplace=True)\n",
    "    df = data_file.hhid.value_counts()\n",
    "    data_file = data_file[data_file.hhid.isin(df.index[df.lt(5)])]\n",
    "    data_file.drop(['hhid'], 1, inplace=True)\n",
    "    data_file = data_file[data_file['smsastat'] == 'Metropolitan']\n",
    "    \n",
    "    \n",
    "    data_file.drop(['smsastat', 'centcity', 'icntcity', 'msafips', 'cmsacode', 'county', 'icntcity', ], 1, inplace=True)\n",
    "    \n",
    "    data_file = data_file[~data_file.smsa93.isna()]\n",
    "    data_file = data_file[~data_file.earnwke.isna()]\n",
    "    size = data_file.smsa93\n",
    "    data_file.drop(['smsa93'], 1, inplace=True)\n",
    "    \n",
    "    data_ext = pandas.get_dummies(data_file, dummy_na = True)\n",
    "    data_file = data_ext.fillna(value = -1)\n",
    "    data_file = pandas.concat([data_file, size], axis = 1)\n",
    "    \n",
    "    small_list = ['100,000 - 249,999', '250,000 - 499,999', '500,000 - 999,999']\n",
    "    data_metropolitan_big = data_file[~data_file.smsa93.isin(small_list)]\n",
    "    data_non = data_file[data_file.smsa93.isin(small_list)]\n",
    "    data_metropolitan_big.drop(['smsa93'], 1, inplace=True)\n",
    "    data_non.drop(['smsa93'], 1, inplace=True)\n",
    "    \n",
    "    x_1, y_1 = separate(data_metropolitan_big, 'earnwke')\n",
    "    x_2, y_2 = separate(data_non, 'earnwke')\n",
    "    \n",
    "    return x_1, y_1, x_2, y_2\n",
    "\n",
    "def stada_to_panda():\n",
    "\n",
    "    file_lis = ['morg01', 'morg02']\n",
    "    \n",
    "    df = read(file_lis[0])\n",
    "    \n",
    "    for i in file_lis[1:]:\n",
    "        df = df.append(read(i))\n",
    "    \n",
    "    x_1, y_1, x_2, y_2 = process_stada(df)\n",
    "    \n",
    "    return x_1, y_1, x_2, y_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1, y_1, x_2, y_2 = stada_to_panda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural net #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_size = x_1.shape[1]\n",
    "\n",
    "net_1 = net(first_layer_size)\n",
    "net_2 = net(first_layer_size)\n",
    "\n",
    "opt1 = Adam(net_1.parameters(), lr = 0.0005)\n",
    "opt2 = Adam(net_2.parameters(), lr = 0.0005)\n",
    "\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(500)):\n",
    "    y_hat = net_1(x_1).squeeze()\n",
    "    \n",
    "    loss = loss_func(y_hat, y_1)\n",
    "    loss.backward()\n",
    "    opt1.step()\n",
    "    net_1.zero_grad()\n",
    "    opt1.zero_grad()\n",
    "    \n",
    "    y_hat = net_2(x_2).squeeze()\n",
    "    \n",
    "    loss = loss_func(y_hat, y_2)\n",
    "    loss.backward()\n",
    "    opt2.step()\n",
    "    net_2.zero_grad()\n",
    "    opt2.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_1 = net_1(x_1)\n",
    "y_hat_2 = net_2(x_1)\n",
    "\n",
    "print(torch.mean(y_hat_1- y_hat_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matching #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_metrix = torch.cdist(x_1, x_2)\n",
    "\n",
    "y_match = torch.zeros_like(y_hat_1)\n",
    "\n",
    "for i in range(y_match.shape[1]):\n",
    "    argmin = torch.argmin(similarity_metrix[i])\n",
    "    y_match = y_1[i] - y_2[argmin]\n",
    "\n",
    "print(torch.mean(y_match))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
